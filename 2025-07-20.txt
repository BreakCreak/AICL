(AICL) root@7836ba81ff57:~/yolo/AICL#     bash ./scripts/train.sh
[0.3194 0.2905 0.2586 0.2206 0.1663 0.1125 0.0609]
epoch=    3  step=   50  Loss=4.7942  cls_acc=50.00  best_map=20.41
[0.4472 0.4064 0.3623 0.3045 0.2327 0.1610 0.0882]
epoch=    7  step=  100  Loss=3.6501  cls_acc=63.33  best_map=28.60
[0.5145 0.4676 0.4135 0.3463 0.2677 0.1884 0.1023]
epoch=   11  step=  150  Loss=2.9776  cls_acc=69.05  best_map=32.86
[0.5607 0.5126 0.4576 0.3813 0.2983 0.2062 0.1192]
epoch=   15  step=  200  Loss=2.5683  cls_acc=70.48  best_map=36.23
[0.6116 0.5601 0.4979 0.4127 0.3236 0.2282 0.1341]
epoch=   19  step=  250  Loss=2.3464  cls_acc=78.10  best_map=39.54
[0.6382 0.5855 0.5219 0.4328 0.3335 0.2353 0.1384]
epoch=   23  step=  300  Loss=2.1635  cls_acc=81.43  best_map=41.22
[0.6489 0.5978 0.5298 0.4402 0.3432 0.2417 0.1409]
epoch=   26  step=  350  Loss=2.0197  cls_acc=83.33  best_map=42.04
[0.6532 0.6001 0.5332 0.4422 0.3418 0.2425 0.1428]
epoch=   30  step=  400  Loss=1.9189  cls_acc=82.86  best_map=42.23
[0.6612 0.6077 0.5382 0.4507 0.3477 0.2457 0.1432]
epoch=   34  step=  450  Loss=1.8465  cls_acc=82.86  best_map=42.78
[0.6683 0.6166 0.5453 0.4554 0.3522 0.2478 0.1476]
epoch=   38  step=  500  Loss=1.7879  cls_acc=83.33  best_map=43.33
[0.6736 0.6256 0.5533 0.4645 0.3605 0.2514 0.1449]
epoch=   42  step=  550  Loss=1.7077  cls_acc=85.24  best_map=43.91
[0.6765 0.6259 0.5531 0.4603 0.3533 0.2517 0.1438]
epoch=   46  step=  600  Loss=1.6821  cls_acc=84.76  best_map=43.91
[0.6706 0.6184 0.5480 0.4576 0.3549 0.2470 0.1501]
epoch=   49  step=  650  Loss=1.6238  cls_acc=83.33  best_map=43.91
[0.6808 0.6311 0.5592 0.4659 0.3599 0.2542 0.1482]
epoch=   53  step=  700  Loss=1.6038  cls_acc=86.67  best_map=44.28
[0.6780 0.6274 0.5538 0.4639 0.3575 0.2513 0.1532]
epoch=   57  step=  750  Loss=1.5702  cls_acc=83.33  best_map=44.28
[0.6794 0.6324 0.5588 0.4624 0.3596 0.2546 0.1477]
epoch=   61  step=  800  Loss=1.5164  cls_acc=84.29  best_map=44.28
[0.6744 0.6296 0.5589 0.4682 0.3632 0.2512 0.1466]
epoch=   65  step=  850  Loss=1.4949  cls_acc=84.29  best_map=44.28
[0.6803 0.6321 0.5598 0.4709 0.3643 0.2563 0.1481]
epoch=   69  step=  900  Loss=1.4651  cls_acc=86.19  best_map=44.45
[0.6870 0.6380 0.5666 0.4734 0.3651 0.2564 0.1505]
epoch=   73  step=  950  Loss=1.4335  cls_acc=85.24  best_map=44.82
[0.6858 0.6384 0.5652 0.4755 0.3643 0.2561 0.1532]
epoch=   76  step= 1000  Loss=1.3942  cls_acc=83.81  best_map=44.84
[0.6837 0.6389 0.5665 0.4771 0.3654 0.2558 0.1551]
epoch=   80  step= 1050  Loss=1.3826  cls_acc=85.24  best_map=44.89
[0.6864 0.6409 0.5657 0.4733 0.3629 0.2523 0.1524]
epoch=   84  step= 1100  Loss=1.3415  cls_acc=85.71  best_map=44.89
[0.6827 0.6366 0.5629 0.4696 0.3581 0.2505 0.1489]
epoch=   88  step= 1150  Loss=1.3112  cls_acc=85.24  best_map=44.89
[0.6801 0.6368 0.5653 0.4715 0.3616 0.2507 0.1484]
epoch=   92  step= 1200  Loss=1.2983  cls_acc=84.29  best_map=44.89
[0.6758 0.6331 0.5630 0.4698 0.3612 0.2490 0.1497]
epoch=   96  step= 1250  Loss=1.2697  cls_acc=85.24  best_map=44.89
[0.6770 0.6331 0.5641 0.4750 0.3633 0.2485 0.1526]
epoch=   99  step= 1300  Loss=1.2553  cls_acc=83.81  best_map=44.89
[0.6705 0.6282 0.5586 0.4712 0.3601 0.2479 0.1486]
epoch=  103  step= 1350  Loss=1.2464  cls_acc=84.29  best_map=44.89
[0.6810 0.6376 0.5643 0.4736 0.3608 0.2491 0.1482]
epoch=  107  step= 1400  Loss=1.2113  cls_acc=85.24  best_map=44.89
[0.6778 0.6337 0.5639 0.4745 0.3666 0.2528 0.1517]
epoch=  111  step= 1450  Loss=1.1977  cls_acc=85.71  best_map=44.89
[0.6778 0.6343 0.5640 0.4784 0.3691 0.2550 0.1528]
epoch=  115  step= 1500  Loss=1.1766  cls_acc=82.86  best_map=44.89
[0.6794 0.6349 0.5578 0.4727 0.3658 0.2536 0.1545]
epoch=  119  step= 1550  Loss=1.1776  cls_acc=83.33  best_map=44.89
[0.6749 0.6314 0.5622 0.4738 0.3646 0.2509 0.1524]
epoch=  123  step= 1600  Loss=1.1425  cls_acc=82.86  best_map=44.89
[0.6791 0.6364 0.5640 0.4751 0.3642 0.2528 0.1521]
epoch=  126  step= 1650  Loss=1.1342  cls_acc=84.29  best_map=44.89
[0.6798 0.6390 0.5635 0.4750 0.3652 0.2522 0.1510]
epoch=  130  step= 1700  Loss=1.1232  cls_acc=84.29  best_map=44.89
[0.6770 0.6324 0.5627 0.4733 0.3623 0.2505 0.1515]
epoch=  134  step= 1750  Loss=1.1114  cls_acc=83.81  best_map=44.89
[0.6812 0.6368 0.5685 0.4767 0.3686 0.2529 0.1536]
epoch=  138  step= 1800  Loss=1.0868  cls_acc=83.33  best_map=44.89
[0.6792 0.6357 0.5672 0.4778 0.3645 0.2512 0.1512]
epoch=  142  step= 1850  Loss=1.0928  cls_acc=84.29  best_map=44.89
[0.6776 0.6350 0.5627 0.4757 0.3639 0.2511 0.1530]
epoch=  146  step= 1900  Loss=1.0647  cls_acc=83.81  best_map=44.89
[0.6829 0.6414 0.5659 0.4783 0.3667 0.2551 0.1519]
epoch=  149  step= 1950  Loss=1.0518  cls_acc=83.33  best_map=44.89
[0.6794 0.6367 0.5647 0.4769 0.3682 0.2556 0.1524]
epoch=  153  step= 2000  Loss=1.0457  cls_acc=82.86  best_map=44.89
[0.6829 0.6409 0.5663 0.4791 0.3671 0.2565 0.1538]
epoch=  157  step= 2050  Loss=1.0343  cls_acc=83.81  best_map=44.95
[0.6794 0.6361 0.5676 0.4746 0.3664 0.2552 0.1552]
epoch=  161  step= 2100  Loss=1.0171  cls_acc=82.38  best_map=44.95
[0.6832 0.6407 0.5720 0.4782 0.3690 0.2524 0.1532]
epoch=  165  step= 2150  Loss=1.0070  cls_acc=82.86  best_map=44.98
[0.6850 0.6439 0.5679 0.4813 0.3674 0.2564 0.1529]
epoch=  169  step= 2200  Loss=1.0007  cls_acc=84.76  best_map=45.07
[0.6774 0.6332 0.5671 0.4773 0.3649 0.2515 0.1477]
epoch=  173  step= 2250  Loss=0.9981  cls_acc=82.86  best_map=45.07
[0.6819 0.6365 0.5685 0.4773 0.3662 0.2492 0.1520]
epoch=  176  step= 2300  Loss=0.9752  cls_acc=83.81  best_map=45.07
[0.6856 0.6383 0.5605 0.4762 0.3669 0.2558 0.1582]
epoch=  180  step= 2350  Loss=0.9730  cls_acc=83.33  best_map=45.07
[0.6805 0.6392 0.5680 0.4783 0.3699 0.2550 0.1537]
epoch=  184  step= 2400  Loss=0.9770  cls_acc=82.86  best_map=45.07
[0.6790 0.6358 0.5648 0.4758 0.3644 0.2524 0.1519]
epoch=  188  step= 2450  Loss=0.9418  cls_acc=82.38  best_map=45.07
[0.6816 0.6389 0.5685 0.4770 0.3708 0.2529 0.1528]
epoch=  192  step= 2500  Loss=0.9426  cls_acc=82.86  best_map=45.07
[0.6856 0.6421 0.5675 0.4795 0.3689 0.2589 0.1563]
epoch=  196  step= 2550  Loss=0.9445  cls_acc=83.33  best_map=45.12
[0.6811 0.6380 0.5678 0.4769 0.3694 0.2517 0.1519]
epoch=  199  step= 2600  Loss=0.9255  cls_acc=83.33  best_map=45.12
[0.6826 0.6394 0.5693 0.4789 0.3725 0.2546 0.1524]
epoch=  203  step= 2650  Loss=0.9220  cls_acc=82.86  best_map=45.12
[0.6820 0.6377 0.5687 0.4776 0.3706 0.2545 0.1519]
epoch=  207  step= 2700  Loss=0.9007  cls_acc=82.86  best_map=45.12
[0.6741 0.6294 0.5637 0.4694 0.3607 0.2517 0.1447]
epoch=  211  step= 2750  Loss=0.8933  cls_acc=82.86  best_map=45.12
[0.6813 0.6391 0.5713 0.4768 0.3649 0.2546 0.1498]
epoch=  215  step= 2800  Loss=0.9096  cls_acc=84.29  best_map=45.12
[0.6796 0.6367 0.5686 0.4762 0.3609 0.2527 0.1491]
epoch=  219  step= 2850  Loss=0.8853  cls_acc=84.29  best_map=45.12
[0.6803 0.6370 0.5681 0.4759 0.3644 0.2520 0.1530]
epoch=  223  step= 2900  Loss=0.8606  cls_acc=83.81  best_map=45.12
[0.6761 0.6321 0.5669 0.4715 0.3561 0.2515 0.1460]
epoch=  226  step= 2950  Loss=0.8628  cls_acc=82.38  best_map=45.12
[0.6822 0.6386 0.5694 0.4777 0.3712 0.2523 0.1527]
epoch=  230  step= 3000  Loss=0.8507  cls_acc=83.33  best_map=45.12
[0.6771 0.6339 0.5669 0.4736 0.3616 0.2512 0.1443]
epoch=  234  step= 3050  Loss=0.8578  cls_acc=82.38  best_map=45.12
[0.6746 0.6321 0.5674 0.4719 0.3613 0.2505 0.1441]
epoch=  238  step= 3100  Loss=0.8367  cls_acc=82.38  best_map=45.12
[0.6729 0.6301 0.5652 0.4713 0.3576 0.2476 0.1430]
epoch=  242  step= 3150  Loss=0.8419  cls_acc=82.86  best_map=45.12
[0.6795 0.6365 0.5691 0.4737 0.3624 0.2504 0.1470]
epoch=  246  step= 3200  Loss=0.8421  cls_acc=83.33  best_map=45.12
[0.6839 0.6394 0.5691 0.4768 0.3712 0.2576 0.1518]
epoch=  249  step= 3250  Loss=0.8203  cls_acc=84.29  best_map=45.12
[0.6767 0.6304 0.5635 0.4704 0.3608 0.2483 0.1419]
epoch=  253  step= 3300  Loss=0.8143  cls_acc=83.81  best_map=45.12
[0.6769 0.6337 0.5675 0.4721 0.3591 0.2512 0.1452]
epoch=  257  step= 3350  Loss=0.8017  cls_acc=81.90  best_map=45.12
[0.6721 0.6288 0.5625 0.4652 0.3570 0.2464 0.1429]
epoch=  261  step= 3400  Loss=0.7968  cls_acc=82.38  best_map=45.12
[0.6749 0.6291 0.5636 0.4698 0.3579 0.2492 0.1449]
epoch=  265  step= 3450  Loss=0.7890  cls_acc=82.86  best_map=45.12
[0.6789 0.6333 0.5651 0.4748 0.3622 0.2516 0.1510]
epoch=  269  step= 3500  Loss=0.8063  cls_acc=83.33  best_map=45.12
[0.6742 0.6308 0.5627 0.4654 0.3568 0.2452 0.1401]
epoch=  273  step= 3550  Loss=0.7781  cls_acc=82.86  best_map=45.12
[0.6811 0.6356 0.5661 0.4745 0.3639 0.2552 0.1539]
epoch=  276  step= 3600  Loss=0.7790  cls_acc=82.38  best_map=45.12
[0.6715 0.6268 0.5607 0.4680 0.3599 0.2476 0.1426]
epoch=  280  step= 3650  Loss=0.7737  cls_acc=82.38  best_map=45.12
[0.6723 0.6274 0.5632 0.4671 0.3545 0.2459 0.1431]
epoch=  284  step= 3700  Loss=0.7530  cls_acc=82.86  best_map=45.12
[0.6747 0.6296 0.5636 0.4694 0.3612 0.2493 0.1428]
epoch=  288  step= 3750  Loss=0.7606  cls_acc=82.38  best_map=45.12
[0.6772 0.6299 0.5643 0.4690 0.3608 0.2545 0.1465]
epoch=  292  step= 3800  Loss=0.7526  cls_acc=82.38  best_map=45.12
[0.6719 0.6293 0.5616 0.4644 0.3570 0.2439 0.1394]
epoch=  296  step= 3850  Loss=0.7448  cls_acc=81.43  best_map=45.12
[0.6775 0.6310 0.5649 0.4677 0.3589 0.2518 0.1486]
epoch=  299  step= 3900  Loss=0.7381  cls_acc=82.86  best_map=45.12
[0.6755 0.6309 0.5609 0.4691 0.3598 0.2510 0.1498]
epoch=  303  step= 3950  Loss=0.7326  cls_acc=82.86  best_map=45.12
[0.6725 0.6261 0.5601 0.4648 0.3597 0.2459 0.1405]
epoch=  307  step= 4000  Loss=0.7260  cls_acc=81.90  best_map=45.12
[0.6752 0.6290 0.5630 0.4677 0.3603 0.2484 0.1408]
epoch=  311  step= 4050  Loss=0.7264  cls_acc=84.29  best_map=45.12
[0.6753 0.6301 0.5631 0.4673 0.3575 0.2511 0.1467]
epoch=  315  step= 4100  Loss=0.7171  cls_acc=82.38  best_map=45.12
[0.6732 0.6278 0.5627 0.4672 0.3618 0.2527 0.1436]
epoch=  319  step= 4150  Loss=0.7119  cls_acc=82.38  best_map=45.12
[0.6815 0.6359 0.5679 0.4724 0.3612 0.2523 0.1505]
epoch=  323  step= 4200  Loss=0.7035  cls_acc=83.81  best_map=45.12
[0.6759 0.6289 0.5631 0.4679 0.3593 0.2510 0.1467]
epoch=  326  step= 4250  Loss=0.7019  cls_acc=83.33  best_map=45.12
[0.6743 0.6284 0.5620 0.4660 0.3583 0.2472 0.1418]
epoch=  330  step= 4300  Loss=0.6817  cls_acc=82.86  best_map=45.12
